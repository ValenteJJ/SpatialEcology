---
title: "Resource selection"
output:
  html_document:
    df_print: paged
---

```{r}
require(terra)
require(tidyterra)
require(sf)
require(adehabitatHR)
require(adehabitatLT)
require(adehabitatHS)
require(tidyverse)
require(survival)
```


# Quick background

For this lab, we're going to continue working with radiotelemetry data from Florida panthers (*Puma concolor coryi*) recorded in south Florida. The Florida panther is critically endangered, and there has been a push to understand space use, home ranges, and resource selection. After being collared with radio transmitters, individual panthers are relocated periodically (every 1-3 days) using airplanes. Most of the telemetry locations are recorded during the morning (7:00 am to 12:00 pm) which is a period of time when panthers are typically resting. We're going to be using data from 6 panthers, 3 of which are adults, and 3 of which are subadults.

Recall that last week we used information on the utilization distributions for these cats to build home ranges using 4 different approaches - minimum convex polygons, kernel density estimates, LoCoH, and Brownian bridge. This week, we're going to move beyond thinking about the home range, but use the same data to understand resource selection at the point, step, and path levels.


# The data

First we are going to bring in a landcover raster. This landcover map has been aggregated at a 500 m resolution which reflects the approximate grain of telemetry error estimated in this study (489 m). This map was generated by the Florida Fish and Wildlife Commission and contains 43 landcover types, so we're going to simplify it a bit.

```{r}


land = rast('https://github.com/ValenteJJ/SpatialEcology/raw/main/Week10/panther_landcover.tif')


classification = read.table('https://raw.githubusercontent.com/ValenteJJ/SpatialEcology/main/Week10/landcover%20reclass.txt', header=T) 

head(classification)

unique(classification$Description2)

land = classify(land, classification[,c(1,3)])
land = categories(land, value=unique(classification[,c(3,4)]))
plot(land)


```



Now we're going to bring in the panther telemetry location data. Note that each observation has a X and Y coordinate, an ID for the individual animal, its age class, and a date on which the observation was recorded. 



```{r}

panthers = st_read('/vsicurl/https://github.com/ValenteJJ/SpatialEcology/raw/main/Week10/panthers.shp') %>% 
  mutate(CatID = as.factor(CatID))

summary(panthers)
unique(panthers$CatID)

```

Note that the CRS for the raster and shapefile is the same, so we don't have to do any spatial transformations. Therefore, we can just plot them on top of one another.

```{r}

crs(land, proj=T) == crs(panthers, proj=T)


ggplot()+
  geom_spatraster(data = land, aes(fill=Description2))+
  scale_fill_manual(values = terrain.colors(14))+
  geom_sf(data = panthers, aes(shape=CatID))

```


We're also going to create layers that represent focal neighborhood summaries of upland and wetland forests which have been shown to be important for Florida panther resource selection. We're going to calculate the proportion of each forest type within a 5 km radius which is a spatial scale that roughly reflects the median distance moved between successive points in this dataset.

```{r}

#Wet forest
wetForest = land
values(wetForest) = 0
wetForest[land %in% c(10,12)] = 1

probMatrix = focalMat(wetForest, 5000, type='circle', fillNA=FALSE)
wetFocal = focal(wetForest, probMatrix, fun='sum', na.rm=T)


#Dry forest
dryForest = land
values(dryForest) = 0
dryForest[land %in% c(11, 13)] = 1

probMatrix = focalMat(dryForest, 5000, type='circle', fillNA=FALSE)
dryFocal = focal(dryForest, probMatrix, fun='sum', na.rm=T)

```

Now we can stack these rasters up and visualize them.

```{r}

layers = c(land, wetFocal, dryFocal)
names(layers) = c('landcover', 'wetForest', 'dryForest')
plot(layers)

```



We're also going to create layers that represent focal neighborhood summaries of upland and wetland forests which have been shown to be important for Florida panther resource selection. We're going to calculate the proportion of each forest type within a 5 km radius which is a spatial scale that roughly reflects the median distance moved between successive points in this dataset.

```{r}

#Wet forest
wetForest = land
values(wetForest) = 0
wetForest[land %in% c(10,12)] = 1

probMatrix = focalMat(wetForest, 5000, type='circle', fillNA=FALSE)
wetFocal = focal(wetForest, probMatrix, fun='sum', na.rm=T)


#Dry forest
dryForest = land
values(dryForest) = 0
dryForest[land %in% c(11, 13)] = 1

probMatrix = focalMat(dryForest, 5000, type='circle', fillNA=FALSE)
dryFocal = focal(dryForest, probMatrix, fun='sum', na.rm=T)

```

Now we can stack these rasters up and visualize them.

```{r}

layers = c(land, wetFocal, dryFocal)
names(layers) = c('landcover', 'wetForest', 'dryForest')
plot(layers)

```




# Point selection functions

Recall that when we discussed study designs for evaluating resource selection we talked about 4 types. 

Design I involves sampling at the population-leve where you have no individually identifiable information.

Design II involves comparing use by individuals to availability at the population level.

Design III requires comparisons of individual-specific use and availability.

Design IV means repeatedly measuring use and availability for the same individual over time.

### Use and availability data for design II analysis

We're going to be using several functions from the adehabitatHS package which focuses on tools for evaluating habitat selection (HS), a.k.a., resource selection. First, we're going to be using the wi() group of functions for calculating Manly's statistic that evaluates proportion of points in a certain landcover type relative to what's available in that landcover type. To do this, we first need to organize the use data into a very specific format where each row represents an individual and each column represents a landcover type.


```{r}

use = terra::extract(layers, panthers) %>% #extract landcover data for each point recorded on each panther
  data.frame() %>% 
  mutate(CatID = as.factor(panthers$CatID)) %>% 
  group_by(CatID, landcover) %>% #this line and the next are used to count how many points fell in each landcover type for each panther
  summarise(n = n()) %>% 
  ungroup() %>% 
  arrange(landcover) %>% 
  pivot_wider(names_from = landcover, values_from = n, values_fill=0) %>% #Pivot_wider is a spectacular function that takes your data from long format to wide format.
  data.frame()
row.names(use) = use$CatID #We need to assign the rownames as the names of the individual panthers, then drop the CatID column
use$CatID = NULL
```

Now we are going to generate 1000 random samples to represent what is available to our panthers. Note that the random points cover our entire study region of interest. Thus, the "available" data we are generating are representative of the entire study region. 

```{r}
set.seed(8)
randII = spatSample(land, size=1000, as.points=T) #Take a random sample of 1000 locations from our landcover raster
randIILand = data.frame(randII) #Convert this to a dataframe
table(randIILand) #Look at it
```

We again need to reshape our data to match the format described above. This time, instead of having an individual row for each panther, we have only 1 row representing the landcover types available to all panthers.

```{r}
availII = randIILand %>% 
  group_by(Description2) %>% #This and the next line count the number of points in each landcover type
  summarise(n = n()) %>% 
  ungroup() %>% 
  rename(landcover = Description2) %>% 
  filter(!(is.na(landcover) | landcover=='Exotics')) %>% #I'm just getting rid of any points that fell in the exotics category because there are so few of them and none of the "use" points fell in that category.
  pivot_wider(names_from = landcover, values_from = n)
```



### Use and availability data for design III analysis

We're going to now consider a different set of availability points that are panther-specific. To do that, we're going to identify a MCP for eacn panther and then sample random points from within that MCP. Why might we want to do that? 

```{r}
set.seed(46)

panthersSp = as(panthers, 'Spatial') #Create a spatial panthers object

catUnique = unique(panthers$CatID) #Make a list of unique cat names

randIII = matrix(nrow=0, ncol=3) #Create a matrix in which to record random points with the landcover data

#This for loop 

for(i in 1:length(catUnique)){
  id.i = catUnique[i] #Select a specific panther
  cat.i = panthersSp[panthersSp$CatID==id.i,] #subset the point data for a specific panther
  mcp.i = mcp(SpatialPoints(coordinates(cat.i)), percent=99) #Calculate the 99% MCP for this panther
  rand.i = spsample(mcp.i, type='random', n=200) #Create 200 random points within the MCP
  rand.i = st_as_sf(rand.i) #Convert these points to an SF object
  rand.i.sample = terra::extract(land, rand.i) #Extract landcover data for these random points
  
  cat.name.i = rep(catUnique[i], length(rand.i))
  rand.cat.i = cbind(cat.name.i, rand.i.sample)
  randIII = rbind(randIII, rand.cat.i)

}

#There are 3 columns in this dataset. Cat, point number, and landcover. We don't need the second.
randIII = data.frame(randIII)[,c(1,3)] %>% 
  mutate(cat.name.i = as.factor(cat.name.i)) %>% 
  setNames(c('cat.i', 'landcover'))

#And now I'm formatting this dataset for our wi() functions.
availIII = randIII %>% 
  group_by(cat.i, landcover) %>% 
  summarise(n = n()) %>% 
  ungroup() %>% 
  filter(!(is.na(landcover) | landcover=='Exotics')) %>% 
  pivot_wider(names_from = landcover, values_from = n, values_fill=0) 




```


### Selection ratios

We now have used vs. availability data for two different study design structures. Let's start by calculating wi for all of the landcover types in the design II dataset. We do this with the widesII() function. 


```{r}
selRatioII = widesII(u = use, 
                     a = as.vector(as.matrix(availII)),
                     avknown = F,
                     alpha = 0.05)
print('Wi')
selRatioII$wi
print('SE Wi')
selRatioII$se.wi
```

And we can pull the wi() values out of this resulting object and plot them to see evidence for selection.

```{r}

tmp = data.frame('category' = names(selRatioII$wi),
                 'wi' = selRatioII$wi,
                 'ucl' = selRatioII$ICwiupper,
                 'lcl' = selRatioII$ICwilower) %>% 
  arrange(desc(wi)) %>% 
  mutate(category = factor(as.character(category), levels=category)) #This line is necessary to re-order the factor levels so that they are plotted in descending order of wi

ggplot(tmp, aes(x=category, y=wi))+
  geom_point()+
  geom_errorbar(aes(ymin=lcl, ymax=ucl))+
  geom_hline(yintercept=1, col='red', linetype='dashed')+
  theme_bw()+
  theme(axis.text.x = element_text(angle=90, vjust=0.3, hjust=1))
```

And we can do it for study design III now.

```{r}

selRatioIII = widesIII(u = use,
                       a = availIII[,2:14],
                       avknown=F, alpha=0.5)
selRatioIII
print('Wi')
selRatioIII$wi
print('SE Wi')
selRatioIII$se.wi
```

```{r}

tmp = data.frame('category' = names(selRatioIII$wi),
                 'wi' = selRatioIII$wi,
                 'ucl' = selRatioIII$ICwiupper,
                 'lcl' = selRatioIII$ICwilower) %>% 
  arrange(desc(wi)) %>% 
  mutate(category = factor(as.character(category), levels=category))

ggplot(tmp, aes(x=category, y=wi))+
  geom_point()+
  geom_errorbar(aes(ymin=lcl, ymax=ucl))+
  geom_hline(yintercept=1, col='red', linetype='dashed')+
  theme_bw()+
  theme(axis.text.x = element_text(angle=90, vjust=0.3, hjust=1))
```


### Logistic regression

Y'all know how to do logistic regression, so we aren't going to spend a ton of time on this. But we could also combine our used and available points then conduct logistic regression to evaluate what factors influence the probability of use (relative to what's available).

```{r}
useCovs = terra::extract(layers, panthers) %>% #Extract covariates for the used points
  select(-ID) %>% 
  mutate(use=1)
backCovs = terra::extract(layers, randII) %>%  #Extract covariates for the available points
  select(-ID) %>% 
  mutate(use=0)
allCovs = rbind(useCovs, backCovs) %>% #Combine them into a 0/1 dataset
  filter(!is.na(landcover))

```

We can now fit logistic regression models. Below I've fit a couple of them and compared them using a likelihood ratio test.

```{r}

rsfAll = glm(use ~ landcover + wetForest + dryForest, family=binomial(link=logit), data=allCovs)
rsfForest = glm(use ~ wetForest + dryForest, family=binomial(link=logit), data=allCovs)

anova(rsfAll, rsfForest, test='LRT')
```

The upshot here is that the model with landcover as a covariate is substantially better than the one that ignores landcover.

# Step selection functions (design IV)

Recall that the big difference between point selection and step selection is the way we define what is available to be used. For a step selection analysis, we need to define availability for every step taken.

```{r}

# This function helps us tease out the date from the recorded DOY
substrRight = function(x, n){
  substr(x, nchar(x) - n+1, nchar(x))
}

#Here we're just creating a spatial object from our panthers sf object. Most of the code is dedicated to converting the DOY information to a real date.
panthersSp = panthers %>% 
  mutate(Juldate = as.character(Juldate)) %>% 
  mutate(date = as.numeric(substrRight(Juldate, 3))) %>% 
  mutate(Date = as.Date(date, origin=as.Date("2006-01-01"))) %>% 
  mutate(Date = as.POSIXct(Date, "%Y-%m-%d", tz='')) %>% 
  as('Spatial')

#And this creates a trajectory object from the x-y coordinates and associated timestamps.
pantherLtraj = as.ltraj(xy=coordinates(panthersSp), date=panthersSp$Date, id=panthersSp$CatID, typeII=T)

plot(pantherLtraj)
plot(pantherLtraj, id='147')
```

We can pull all kinds of great stuff from this Ltraj object.

```{r}
pantherLtraj[[2]]
```

For example, we can look at the distribution of step lengths for panther 2.

```{r}
pantherLtraj[[2]][,6]
hist(pantherLtraj[[2]][,6], main='Second CatID')
```

Or we can look at the distribution of turning angles for panther 2.

```{r}
rose.diag(na.omit(pantherLtraj[[2]][,9]), bins=12, prop=1.5)
circ.plot(pantherLtraj[[2]][,9], pch=1)
```

Steps are a bit complicated. They are comprised of 2 points, so that the distance and turning angle show up in a row for a specific point is a bit confusing. That is to say, we need to be careful when generating potential steps that we're paying attention. Below, I have produced code for generating 3 random steps for each used step.

```{r}

#Create a data frame that has one row per panther per point recorded, along with the x-y coordinates
stepData = data.frame(st_coordinates(panthers)) %>% 
  mutate(CatID = as.factor(panthers$CatID))

#Define how many used steps we observed, and use that to calculate the number of available steps to generate
nUse = nrow(stepData)
nAvail = nUse*3

trajDf = ld(pantherLtraj) #This just converts the trajectory object into a data frame.

#Sample from the distribution of step lengths
availDist = matrix(sample(na.omit(trajDf$dist), size=nAvail, replace=T), ncol=3)

#Sample from the distribution of turning angles
availAngle = matrix(sample(na.omit(trajDf$rel.angle), size=nAvail, replace=T), ncol=3)

colnames(availDist) = c('aDist1', 'aDist2', 'aDist3')
colnames(availAngle) = c('aAngle1', 'aAngle2', 'aAngle3')

trajDf = cbind(trajDf, availDist, availAngle)

```

*Note: often you will see folks take angles and distances from all other individuals, and leave the target individual out to avoid circularity.*

We are left with a data frame that has the recorded step length and turning angle, as well as three possible step lengths and turning angles that could have been taken. We now need x-y coordinates for the endpoints of our possible steps. Note that we can calculate the end point x-y coordinates using a bit of trigonometry. One way to do that is by using the absolute angle describing the path along which the animal moves.

```{r}
trajDf[2,'x'] + trajDf[2,'dist']*cos(trajDf[2,'abs.angle'])
trajDf[2,'y'] + trajDf[2,'dist']*sin(trajDf[2,'abs.angle'])

trajDf[3,c('x', 'y')]
```

We can also calculate end points using the relative angle along which the individual moves, combined with the absolute angle from the previous point.

```{r}
trajDf[2,'x'] + trajDf[2, 'dist']*cos(trajDf[1,'abs.angle'] + trajDf[2,'rel.angle'])
trajDf[2,'y'] + trajDf[2, 'dist']*sin(trajDf[1,'abs.angle'] + trajDf[2,'rel.angle'])
trajDf[3,c('x', 'y')]

```

With this trigonometry refresher in mind, let's find the x-y coordinates for the endpoints of the available steps we generated.

```{r}

#Creating columns in which to store the new values
trajDf$x.t1 = NA
trajDf$y.t1 = NA
trajDf$x.a1 = NA
trajDf$y.a1 = NA
trajDf$x.a2 = NA
trajDf$y.a2 = NA
trajDf$x.a3 = NA
trajDf$y.a3 = NA

#We have to loop over all of the rows. Note, we have to start at row two because you cannot have a turning angle in row 1.
for(i in 2:nrow(trajDf)){
  
  #Pay attention to the ifelse() statements below. We only want to calculate an x-y coordinate for potential points if this particular point was recorded on the same panther as the point above it. Otherwise, we want to treat it as a point 1.
  
  #Calculate x and y coordinates for the used endpoint
  trajDf$x.t1[i] = ifelse(trajDf$id[i] == trajDf$id[i-1], trajDf[i,'x'] + trajDf[i, 'dist']*cos(trajDf[i-1,'abs.angle'] + trajDf[i,'rel.angle']), NA)
  trajDf$y.t1[i] = ifelse(trajDf$id[i] == trajDf$id[i-1], trajDf[i,'y'] + trajDf[i, 'dist']*sin(trajDf[i-1,'abs.angle'] + trajDf[i,'rel.angle']), NA)
  
  #Calcoulate x and y coordinates for the first available endpoint
  trajDf$x.a1[i] = ifelse(trajDf$id[i] == trajDf$id[i-1], trajDf[i,'x'] + trajDf[i, 'aDist1']*cos(trajDf[i-1,'abs.angle'] + trajDf[i,'aAngle1']), NA)
  trajDf$y.a1[i] = ifelse(trajDf$id[i] == trajDf$id[i-1], trajDf[i,'y'] + trajDf[i, 'aDist1']*sin(trajDf[i-1,'abs.angle'] + trajDf[i,'aAngle1']), NA)
  
  #Calculate x and y coordinates for the second available endpoint
  trajDf$x.a2[i] = ifelse(trajDf$id[i] == trajDf$id[i-1], trajDf[i,'x'] + trajDf[i, 'aDist2']*cos(trajDf[i-1,'abs.angle'] + trajDf[i,'aAngle2']), NA)
  trajDf$y.a2[i] = ifelse(trajDf$id[i] == trajDf$id[i-1], trajDf[i,'y'] + trajDf[i, 'aDist2']*sin(trajDf[i-1,'abs.angle'] + trajDf[i,'aAngle2']), NA)
  
  #Calculate x and y coordinates for the third available endpoint
  trajDf$x.a3[i] = ifelse(trajDf$id[i] == trajDf$id[i-1], trajDf[i,'x'] + trajDf[i, 'aDist3']*cos(trajDf[i-1,'abs.angle'] + trajDf[i,'aAngle3']), NA)
  trajDf$y.a3[i] = ifelse(trajDf$id[i] == trajDf$id[i-1], trajDf[i,'y'] + trajDf[i, 'aDist3']*sin(trajDf[i-1,'abs.angle'] + trajDf[i,'aAngle3']), NA)
}


```



To now analyze these data using conditional logistic regression, we need to switch to long format.

```{r}

#Start by getting rid of any rows with missing data (e.g., because they represent the first point taken on a panther)
trajDf = trajDf[complete.cases(trajDf),]

#Subset the data for the used points
trajUse = data.frame(use = rep(1, nrow(trajDf)),
                     trajDf[,c('id', 'pkey', 'date', 'x.t1', 'y.t1')]) %>% 
  setNames(c('use', 'id', 'pair', 'date', 'x', 'y'))

#Subset the data for the first available points
trajA1 = data.frame(use = rep(0, nrow(trajDf)),
                     trajDf[,c('id', 'pkey', 'date', 'x.a1', 'y.a1')]) %>% 
  setNames(c('use', 'id', 'pair', 'date', 'x', 'y'))

#Subset the data for the second available points
trajA2 = data.frame(use = rep(0, nrow(trajDf)),
                     trajDf[,c('id', 'pkey', 'date', 'x.a2', 'y.a2')]) %>% 
  setNames(c('use', 'id', 'pair', 'date', 'x', 'y'))

#Subset the data for the third available points
trajA3 = data.frame(use = rep(0, nrow(trajDf)),
                     trajDf[,c('id', 'pkey', 'date', 'x.a3', 'y.a3')]) %>% 
  setNames(c('use', 'id', 'pair', 'date', 'x', 'y'))
```


Note that because we retained this pair variable, we can use that to match the available steps specific to each of the used steps. Below we rbind the 4 datasets together and then extract the covariates of interest from our rasters for each used and available point.

```{r}
stepData = rbind(trajUse, trajA1, trajA2, trajA3)

cov = terra::extract(layers, st_as_sf(stepData, coords=c('x', 'y'), crs=crs(panthers))) %>% 
  select(-ID)

stepData = cbind(stepData, cov)
```

And we can conduct a conditional logistic regression analysis using the clogit() function from the survival package. Note that we identify the matched case-control groups with the strata() argument.

```{r}

#Use as a function of amount of wet and dry forest within 5 km at the endpoint
logitSSF = clogit(use ~ wetForest + dryForest +strata(pair), data=stepData)

#Same model, except we include a random id effect to account for non-independence among repeated points on the same panther.
logitCatSSF = clogit(use ~ wetForest + dryForest + strata(pair) + cluster(id), method='approximate', data=stepData)

logitRSF = glm(use ~ wetForest + dryForest, family='binomial', data=stepData)
```


# Path selection

So we've now looked at selection at the point and step levels. We can also examine patterns in habitat selection at the path level by defining alternative paths the animal didn't take for comparison. There are several functions in the adehabitatLT package that can be used to generate random paths. Let's start simply by just rotating the observed path around it's central location.

```{r}
panther147Traj = pantherLtraj[6]

pathModel = NMs.randomShiftRotation(panther147Traj, rshift=F, rrot=T, nrep=1) #Define how we want the rotation to occur

pathAvail = testNM(pathModel) #Actually simulate the times and points for the new path

pathAvailDf = data.frame(pathAvail[[1]]) #Convert the output to a new data frame

pathAvailLtraj = as.ltraj(xy=pathAvailDf[,c('x', 'y')], date=pathAvailDf[,'date'], id=rep(147, nrow(pathAvailDf))) #Create a ltraj object out of the new path so we can use it as a trajectory


plot(pathAvailLtraj) #Plot the random rotated path
plot(pantherLtraj, id='147') #Plot the original path
```

An alternative for generating random paths is to sort of simulate a correlated random walk based on the distribution of turning angles and step lengths observed from the original dataset. In doing this, we generate a new path with the same starting location, but that takes a random trajectory based on how the animal generally moves.

```{r}
crwModel = NMs.randomCRW(panther147Traj, rangles=T, rdist=T, nrep=1) #Define the details of the simulation

crwAvail = testNM(crwModel) #Actually carry out the simulation

crwAvailDf = data.frame(crwAvail[[1]]) #Convert output to a new data frame

crwAvailLtraj = as.ltraj(xy=crwAvailDf[,c('x', 'y')], date=crwAvailDf[,'date'], id=rep(147, nrow(crwAvailDf))) #Create a ltraj object

#Plot the new path and then the original.
plot(crwAvailLtraj)
plot(pantherLtraj, id='147')
```


