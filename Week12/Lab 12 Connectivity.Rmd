---
title: "Lab 12 - Connectivity"
output:
  html_document:
    df_print: paged
---

```{r, warning=F, message=F}

rm(list=ls())

require(tidyverse)
require(terra)
require(sf)
require(gdistance)
require(igraph)
require(fitdistrplus)
require(fdrtool)
```


# Functional connectivity among Florida Panther protected areas

Today we're going to be working with two different data sets. First, we'll be revisiting our panther data. This time, we'll be trying to identify connectivity and potential corridors among protected lands in south Florida. Prior work used radio telemetry data to interpret landscape resistance based on point-selection and home range selection functions (https://www.sciencedirect.com/science/article/pii/S0006320705005495).

### Datasets

We're going to be relying on two data sets here. The first is the same vegetation raster we've been working with the past few weeks, developed by the Florida Fish and Wildlife Conservation Commission. Secondly, we'll use a shapefile showing boundaries for some protected areas in southern Florida.

```{r}

# Read in the landcover raster
land = rast('https://github.com/ValenteJJ/SpatialEcology/raw/main/Week10/panther_landcover.tif')

# Identify the crs of the landcover raster
crs(land)

#Look at th raster's resolution
res(land)



# Bring in the public lands shapefile
public = st_read('/vsicurl/https://github.com/ValenteJJ/SpatialEcology/raw/main/Week12/panther_publicland.shp')

# Set the crs of the public lands shapefile
st_crs(public) = crs(land)

# And look at it
data.frame(public)
```


For mapping connectivity among these public lands, we need to identify a point in space from which to do the mapping. Thus, we're going to calculate the centroid of each park which is the center of the mass.

```{r, warning=F}
publicCentroids = st_centroid(public)

plot(land)
plot(st_geometry(public), add=T)
plot(st_geometry(publicCentroids), add=T, col='red')
```

We are now going to reclassify this landcover map to represent resistance. To do this, just bring in the table below and use the classify() function. Here higher values represent greater resistance to movement. These values were generated from the paper I referenced above, so have a read if you want more information about how we got to these resistance values. For our purposes, just take these numbers at face value.

```{r}
classification = read.table('https://raw.githubusercontent.com/ValenteJJ/SpatialEcology/main/Week12/resistance%20reclass.txt', header=T)
landCost = classify(land, classification[,c(1,3)])
landCost = raster(landCost)

plot(landCost)
plot(st_geometry(public), add=T)
plot(st_geometry(publicCentroids), add=T, col='red')
```

# Effective distances

There are several ways to calculate "distances" between protected areas, and we will consider 4 of them. The most straightforward metric is Euclidean distance, also known as straight-line distance. This totally ignores the resistance of the landscape and simply assumes that those protected areas that are physically closer are also more connected.

```{r}
#Euclidean distance

geoDist = pointDistance(publicCentroids, lonlat=F)
geoDist = as.dist(geoDist)
geoDist
```

Next we will consider the least-cost distance which is the shortest distance between two points based on sum of costs. We can quantify this either in terms of least-cost distance (cumulative cost of the path) or least-cost path length (actual length of the path that has the least cost). Before we can calculate this, however, we need to use the gdistance package to create a transition layer. This converts the raster cells into a sparse network of connections based on the mean conductance value (1/resistance) between pairs of cells

```{r}
# Calculate conductance transition matrix
landCond = transition(1/landCost, transitionFunction = mean, 8)

#Do a geographic correction of the conductance values to "correct" for the fact that there are further distances between cells that touch on the diagonal
landCond = geoCorrection(landCond, type='c', multpl=F)
```

Now we can calculate the actual least-cost distance using Dijkstra's algorithm.

```{r}

#Least-cost distance
lcDist = costDistance(landCond, st_coordinates(publicCentroids))
lcDist
```

Now we will calculate an effective distance based on circuit theory. We assume random walks, acknowledging that different paths are possible. The commute distance function quantifies the expected time for an individual to move from one point to another in number of steps.


```{r}
#Commute distance
circuitDist = commuteDistance(landCond, st_coordinates(publicCentroids))
circuitDist
```

We could also calculate a randomized shortest path. Recall, that here we have a parameter theta that we can tweak. If theta = 0, our analysis is analogous to a circuit theory approach and as theta increases, we approach a least-cost path. In this case, the rSPDistance() function takes an unfortunately long time, so we are going to subset to just the first two points for this exercise in class.

```{r}
#Randomized shortest path distance
rspDist1.2 = rSPDistance(landCond, from=st_coordinates(publicCentroids)[1,], to=st_coordinates(publicCentroids)[2,], theta=0.001)
rspDist1.2
```


# Mapping least-cost paths

The above code helped us calculate the effective distances among the protected areas, but this is spatial ecology, and we're interested in mapping the literal paths. For this, we're going to subset our protected areas and focus in on two of them: the Florida Panther Wildlife Refuge, and the Okaloacoochee Slough State Forest. To speed up computation, we're going to crop our raster layer to a region relevant to these two protected areas.

```{r}
# Choose the extent for cropping
fpwrOssfExtent = extent(642000, 683000, 237000, 298000)

# Crop the landcover layer
landSub = crop(land, fpwrOssfExtent)

# Crop the cost layer and create a transition matrix
landCostSub = crop(landCost, fpwrOssfExtent)
landCondSub = transition(1/landCostSub, transitionFunction=mean, 8)
landCondSub = geoCorrection(landCondSub, type='c', multpl=F)

```

Now we can use the shortestPath() function to actually map the least-cost path.

```{r}
fpwrOssfLcp = shortestPath(landCond, st_coordinates(publicCentroids)[5,], st_coordinates(publicCentroids[3,]), output='SpatialLines')

plot(landCostSub, axes=F)
plot(st_geometry(public), add=T)
plot(st_geometry(publicCentroids), col='grey30', add=T)
lines(fpwrOssfLcp, col='red', lwd=3)

```


# Least-cost Corridors

One major criticism of least-cost path analysis is that it focuses only on a single line, and thus sort of assumes that all individuals are going to take that one optimal path. One potential alternative is to instead map a least-cost corridor. This requires a few steps. First, we're going to calculate the accumulated cost surface from our two points.

```{r}
fpwrCost = accCost(landCondSub, st_coordinates(publicCentroids)[5,])
ossfCost = accCost(landCondSub, st_coordinates(publicCentroids)[3,])

plot(fpwrCost)
plot(ossfCost)
```

Now we can sum the cumulative values for each cell.

```{r}
leastCostCorridor = overlay(fpwrCost, ossfCost, fun=function(x, y){return(x+y)})

plot(leastCostCorridor)
```

A clear corridor starts to jump out, and now we can filter to those pixels which have the easiest paths. Here, we're going to focus on the 10% of pixels with the least summed cost.

```{r}
#Calculate the 10% quantile for the leastCostCorridor raster
quantile10 = quantile(leastCostCorridor, probs=0.1, na.rm=T)
quantile10

#Create a new raster with a value of 1 if it has a summed cost in the lower 10% and a NA otherwise
leastCostCorridor10 = leastCostCorridor
values(leastCostCorridor10) = NA
leastCostCorridor10[leastCostCorridor < quantile10] = 1

#Plot this raster and look at it
plot(leastCostCorridor10, legend=F, axes=F)
points(publicCentroids, col='grey30')
lines(fpwrOssfLcp, col='red')
```

Now that we have these spatially explicit objects, we can use them to extract information for these paths or corridors for conservation planning purposes. You'll be doing this for one of the challenges in your lab.



# Randomized shortest path (flow mapping)

We can contrast our LCP approach above with a randomized shortest path analysis. Again, we are going to assume a random walk for an individual that is biased based on the resistance encountered. The passage() function quantifies the number of potential movements through cells before arriving in a destination location from a source location.

```{r}
#Random walk

passageMapT0 = passage(landCondSub, origin = st_coordinates(publicCentroids)[3,], goal = st_coordinates(publicCentroids)[5,], theta=0)

plot(passageMapT0)
```

Note that when theta is set to 0, movement probability in each cell is very low and movement is thus very diffuse. Thus we are developing a circuit-theory based solution to our assessment of movement. Theta is the degree from which the path randomly deviates from the shortest path.



# Patch-based networks and graph theory

Now we're going to switch gears and demonstrate the use of patch-based graphs or networks to evaluate connectivity. Importantly, we're going to be working with a completely different dataset and comparing potential vs. realized connectivity among 29 sites for the endangered Snail Kite. First we're going to bring in a node-specific data frame that has name, coordinate, and area information for the 29 sites.

We're going to bring in two datasets. 

```{r}

nodes = read.csv('https://raw.githubusercontent.com/ValenteJJ/SpatialEcology/main/Week12/kite_nodes.csv')
area = nodes$area
nodes
```

Next we will bring in a matrix showing within-breeding-season dispersal. The values in the matrix represent the observed number of Snail Kites that moved between each combination of sites. Note that this is not a symmetric matrix, meaning that we have bi-directional information.

```{r}
aObs = read.csv('https://raw.githubusercontent.com/ValenteJJ/SpatialEcology/main/Week12/kite_movement.csv')[,-1]
diag(aObs) = 0
aObs
```

Now we can create a distance matrix quantifying how far apart the sites are from one another in km.

```{r}
coords = cbind(nodes$XCoord, nodes$YCoord)
distMat = pointDistance(coords, lonlat=F)
distMat = distMat / 1000 # in km
distMat
```

### Dispersal Kernels

Dispersal kernels quantify the dispersal probability as a function of distance from some original location (e.g., natal site or breeding site). Here we are creating dispersal kernels based on within-season movements. What this means is that we are trying to fit a model that represents the distribution of dispersal distances. So we need to pull together the non-zero movement distances and plot them.


```{r}

linkLoc = which(aObs > 0, arr.ind=T)
withinDisp = cbind(distMat[linkLoc], aObs[linkLoc])

#Creating one distance observation for each individual
withinDisp = rep(withinDisp[,1], withinDisp[,2])

hist(withinDisp)
```

Now we can fit 4 different models that could potentially represent this observed distribution. We will focus on the log-normal distribution, exponential, Weibull, and halfnormal.

```{r, warning=F}

dispLnorm = fitdist(data = withinDisp, distr='lnorm', method='mle')
dispExp = fitdist(data = withinDisp, distr='exp', method='mle')
dispWeib = fitdist(data=withinDisp, distr='weibull', method='mle')
disp1dt = fitdist(data=withinDisp, distr='halfnorm', start=list(theta=0.01), method='mle')

dispAic = gofstat(list(dispExp, dispLnorm, dispWeib, disp1dt), fitnames=c('exponential', 'lognormal', 'Weibull', '1Dt'))
dispAic$aic
```

It looks like the Weibull distribution fits best, based on AIC. Nonetheless, we're going to use the exponential distribution given it is commonly used in metapopulation ecology and landscape connectivity research. This requires only one parameter, alpha, which describes the inverse of the mean dispersal distance for a species, and this information is relatively frequently available.

```{r}
plot(dispExp)
```

### Creating a network or graph

Given our chosen dispersal kernel, we can now create graphs based on different transition matrices. Note that we already have one directed, weighted network in aObs.

```{r}
aObs
```

We can also create an undirected, unweighted network based on the mean dispersal distance. Here we are simply assuming that if two sites are closer together than the mean dispersal distance for the Kites, they are connected, and otherwise they are not.

```{r}

# Calculate mean dispersal distance
aMeanDist = mean(withinDisp)
aMeanDist

# Create the transition matrix
aMean = matrix(0, nrow=nrow(aObs), ncol=ncol(aObs))
aMean[distMat < aMeanDist] = 1
diag(aMean) = 0
aMean
```

Lastly, we will try creating an undirected, weighted network where the weights are based on the exponential distribution. Here we are going to use our mean dispersal distance as our estimate for alpha.


```{r}
aProb = matrix(0, nrow=nrow(aObs), ncol=ncol(aObs))
alpha = 1/aMeanDist

# Calculate weights in the distance matrix
aProb = exp(-alpha*distMat)
diag(aProb)=0
aProb
```

Now we create igraph objects based on each matrix.

```{r}
graphAmean = graph_from_adjacency_matrix(aMean, mode='undirected')
graphAprob = graph_from_adjacency_matrix(aProb, mode='undirected', weighted=T)
graphAobs = graph_from_adjacency_matrix(as.matrix(aObs), mode='directed', weighted=T)
```


Now that we have created this igraph structure, we can pull out lots of information about the network structure.

```{r}
plot(graphAmean, layout=coords, vertex.label=NA)
plot(graphAprob, layout=coords, edge.width=E(graphAprob)$weight, vertex.label=NA)
plot(graphAobs, layout=coords, vertex.label=NA)
```


### Patch-scale connectivity

Node- or patch-level connectivity measures are often called (in network speak) "centrality" measures. We can also break such metrics down into "radial" or "medial" measures. Radial measures focus on quantifying flow that starts or terminates from a given patch. Common radial measures include degree (sum of number of links);

```{r}
aMeanDegree = degree(graphAmean)
aMeanDegree
```

strength (sum of weights of links to/from patch);

```{r}
aMeanStrength = strength(graphAprob)
aMeanStrength
```


eigenvector centrality (relative number of indirect links through neighbors);

```{r}
aMeanEigen = eigen_centrality(graphAmean)
aMeanEigen$vector
```

and closeness centrality (inverse of the average shortest-path distance from patch to all other connected patches).

```{r}
aMeanClose = closeness(graphAmean)
aMeanClose
```



Medial measures quantify the number of paths that flow through a patch. The most common one is betweenness centrality which quantifies the number of shortest paths between all patches in the network that go through a particular patch.

```{r}
aProbBetween = betweenness(graphAprob, weights=1/E(graphAprob)$weight)
aProbBetween
```


### Landscape-scale connectivity

Landscape connectivity metrics are used for quantifying connectivity across the entire network. Here we will focus on four landscape metrics. The first is connectance which is a simple measure for unweighted graphs. It is the number of observed links over the total number of possible links.

```{r}
connectance = edge_density(graphAmean)
connectance
```

Next we will look at the integral index of connectivity which is also based on a binary network. Values range from 0 (no habitat) to 1 (entire landscape is habitat), and the value declines with loss of each patch or loss of non-redundant links.

```{r}

AL = 63990 # Approximate study area in km^2

#Create a matrix of shortet paths
nlMat = distances(graphAmean)

#In cases where you have isolated patches, we assign an arbitrarily large value
nlMat [is.infinite(nlMat)] = 1000

iicMat = outer(area, area)/(1+nlMat)
iic = sum(iicMat)/AL^2
iic
```


Lastly, we'll look at probability of connectivity which is one of the most frequently used metrics. This metric is used to describe the probability that two random points in a landscape are reachable from each other given a set of habitat patches and links among them.


```{r}
pStarMat = distances(graphAprob, weights=E(graphAprob)$weight)

# Back-transform to probabilities
pStarMat = exp(-pStarMat)

# Numerator of PC
pcNum = outer(area, area)*pStarMat

# Probability of connectivity
pc = sum(pcNum)/AL^2
pc
```



